import json
import requests
from typing import Dict, Any, Optional
import time
import sys

class LegalConsultationEvaluator:
    def __init__(self, ollama_host: str = "localhost", ollama_port: int = 11434):
        """
        ë²•ë¥  ìƒë‹´ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”

        Args:
            ollama_host: Ollama ì„œë²„ í˜¸ìŠ¤íŠ¸ (IP ì£¼ì†Œ ë˜ëŠ” ë„ë©”ì¸)
            ollama_port: Ollama ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 11434)
        """
        self.ollama_url = f"http://{ollama_host}:{ollama_port}"
        self.model = "gpt-oss:20b"
        print(f"ğŸ”— Ollama ì„œë²„ ì„¤ì •: {self.ollama_url}")

        # ì„œë²„ ì´ˆê¸°í™” ì‹œ ì—°ê²° í™•ì¸ (ìµœëŒ€ 10ë¶„ ëŒ€ê¸°)
        if not self.wait_for_server():
            print("âš ï¸  Ollama ì„œë²„ ì—°ê²°ì„ ê±´ë„ˆëœë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„ë©ë‹ˆë‹¤.")

    def wait_for_server(self, max_wait_seconds: int = 600, check_interval: int = 5) -> bool:
        """
        Ollama ì„œë²„ê°€ ì‹¤í–‰ë  ë•Œê¹Œì§€ ëŒ€ê¸°

        Args:
            max_wait_seconds: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - ê¸°ë³¸ê°’: 600ì´ˆ (10ë¶„)
            check_interval: í™•ì¸ ê°„ê²© (ì´ˆ) - ê¸°ë³¸ê°’: 5ì´ˆ

        Returns:
            ì„œë²„ ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        start_time = time.time()
        attempt = 0

        print(f"â³ Ollama ì„œë²„ ì—°ê²° ëŒ€ê¸° ì¤‘... (ìµœëŒ€ {max_wait_seconds}ì´ˆ)")
        print(f"   í™•ì¸ ê°„ê²©: {check_interval}ì´ˆ")

        while time.time() - start_time < max_wait_seconds:
            attempt += 1
            elapsed = int(time.time() - start_time)

            try:
                # API ìƒíƒœ í™•ì¸
                response = requests.get(f"{self.ollama_url}/api/tags", timeout=3)

                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])

                    if models:
                        model_names = [m["name"] for m in models]
                        print(f"\nâœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ! (ì‹œë„ {attempt}íšŒ, {elapsed}ì´ˆ ê²½ê³¼)")
                        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(model_names)}")

                        if self.model in model_names:
                            print(f"âœ… {self.model} ëª¨ë¸ í™•ì¸ë¨!")
                            return True
                        else:
                            print(f"âš ï¸  {self.model} ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                            print(f"   ëª…ë ¹ì–´: ollama run {self.model}")
                    else:
                        print(f"\râ³ [{elapsed}ì´ˆ] ì„œë²„ëŠ” ì‹¤í–‰ ì¤‘ì´ë‚˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤... (ì‹œë„ {attempt}íšŒ)", end="")

                else:
                    print(f"\râ³ [{elapsed}ì´ˆ] ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})... (ì‹œë„ {attempt}íšŒ)", end="")

            except requests.exceptions.Timeout:
                print(f"\râ³ [{elapsed}ì´ˆ] ì—°ê²° ì‹œê°„ ì´ˆê³¼... (ì‹œë„ {attempt}íšŒ)", end="")

            except requests.exceptions.ConnectionError:
                print(f"\râ³ [{elapsed}ì´ˆ] ì„œë²„ ì—°ê²° ëŒ€ê¸° ì¤‘... (ì‹œë„ {attempt}íšŒ)", end="")

            except Exception as e:
                print(f"\râ³ [{elapsed}ì´ˆ] ì˜¤ë¥˜ ë°œìƒ: {str(e)[:50]}... (ì‹œë„ {attempt}íšŒ)", end="")

            # ìµœëŒ€ ì‹œê°„ì— ë„ë‹¬í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ëŒ€ê¸°
            if time.time() - start_time < max_wait_seconds:
                time.sleep(check_interval)

        # íƒ€ì„ì•„ì›ƒ
        elapsed_total = int(time.time() - start_time)
        print(f"\n\nâŒ {elapsed_total}ì´ˆ ë™ì•ˆ ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt}íšŒ)")
        print(f"   ì„œë²„ ì£¼ì†Œ: {self.ollama_url}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   1. Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("   2. ì„œë²„ ì£¼ì†Œì™€ í¬íŠ¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("   3. ë°©í™”ë²½ ì„¤ì • í™•ì¸")
        print("   4. ì›ê²© ì„œë²„ì˜ ê²½ìš°: OLLAMA_HOST=0.0.0.0 ollama serve")
        return False

    def create_prompt(self, conversation_data: Dict[str, Any]) -> str:
        """
        í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            conversation_data: ëŒ€í™” ë‚´ìš© ë°ì´í„°

        Returns:
            ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        prompt = """ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì£¼ì„ ì—†ì´ JSONë§Œ ì œê³µí•˜ì„¸ìš”.

ë‹¤ìŒ ê³ ê° ìƒë‹´ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  í’ˆì§ˆ í‰ê°€ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.

ë²•ë¥  ìƒë‹´ì´ ì•„ë‹ˆë”ë¼ë„ ì¼ë°˜ì ì¸ ê³ ê° ì„œë¹„ìŠ¤ í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

í•„ìˆ˜ JSON êµ¬ì¡° (ì •í™•íˆ ì´ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ):
{
  "evaluation": {
    "total_score": [0-100 ì‚¬ì´ì˜ ìˆ«ì],
    "positive_aspects": [
      {
        "aspect": "[ì¸¡ë©´ ì´ë¦„ - í•œê¸€ë¡œ]",
        "description": "[ì„¤ëª… - í•œê¸€ë¡œ]",
        "related_segments": [ì¸ë±ìŠ¤ ë°°ì—´]
      }
    ],
    "negative_aspects": [
      {
        "aspect": "[ì¸¡ë©´ ì´ë¦„ - í•œê¸€ë¡œ]",
        "description": "[ì„¤ëª… - í•œê¸€ë¡œ]",
        "related_segments": [ì¸ë±ìŠ¤ ë°°ì—´]
      }
    ],
    "most_impressive": {
      "point": "[í¬ì¸íŠ¸ - í•œê¸€ë¡œ]",
      "description": "[ì„¤ëª… - í•œê¸€ë¡œ]",
      "segment_index": [ì¸ë±ìŠ¤ ë²ˆí˜¸]
    },
    "improvements_needed": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "current_response": "[í˜„ì¬ í…ìŠ¤íŠ¸ - í•œê¸€ë¡œ]",
        "suggestion": "[ì œì•ˆ í…ìŠ¤íŠ¸ - í•œê¸€ë¡œ]",
        "reason": "[ì´ìœ  - í•œê¸€ë¡œ]"
      }
    ],
    "comprehensive_evaluation": {
      "communication_skill": [0-100 ì ìˆ˜],
      "legal_expertise": [0-100 ì ìˆ˜],
      "customer_satisfaction": [0-100 ì ìˆ˜],
      "problem_solving": [0-100 ì ìˆ˜],
      "overall_comment": "[ì´í‰ - í•œê¸€ë¡œ]"
    }
  }
}

ëŒ€í™” ë°ì´í„°:
"""
        # ëŒ€í™” ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
        conversation_str = json.dumps(conversation_data, ensure_ascii=False, indent=2)
        return prompt + conversation_str

    def test_connection(self) -> bool:
        """
        Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        
        Returns:
            ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                
                print(f"âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ!")
                print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(model_names) if model_names else 'ì—†ìŒ'}")
                
                if self.model in model_names:
                    print(f"âœ… {self.model} ëª¨ë¸ í™•ì¸ë¨!")
                    return True
                else:
                    print(f"âš ï¸  {self.model} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    if model_names:
                        print(f"   ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ self.model ê°’ì„ ë³€ê²½í•˜ì„¸ìš”.")
                    else:
                        print(f"   ì›ê²© ì„œë²„ì—ì„œ 'ollama run {self.model}' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    return False
            else:
                print(f"âŒ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False
                
        except requests.exceptions.Timeout:
            print(f"â±ï¸  ì—°ê²° ì‹œê°„ ì´ˆê³¼. ì„œë²„ ì£¼ì†Œë¥¼ í™•ì¸í•˜ì„¸ìš”: {self.ollama_url}")
            return False
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.ollama_url}")
            print(f"   ì˜¤ë¥˜: {str(e)}")
            print("\nğŸ’¡ í™•ì¸ì‚¬í•­:")
            print("   1. ì›ê²© ì„œë²„ì—ì„œ Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
            print("   2. ë°©í™”ë²½ ì„¤ì • í™•ì¸ (í¬íŠ¸ 11434)")
            print("   3. ì›ê²© ì„œë²„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ Ollama ì‹¤í–‰:")
            print("      OLLAMA_HOST=0.0.0.0 ollama serve")
            return False
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False

    def call_ollama(self, prompt: str, retry_count: int = 0) -> Optional[Dict[str, Any]]:
        """
        Ollama API í˜¸ì¶œ

        Args:
            prompt: í‰ê°€ í”„ë¡¬í”„íŠ¸
            retry_count: í˜„ì¬ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            API ì‘ë‹µ ê²°ê³¼
        """
        url = f"{self.ollama_url}/api/generate"
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1 if retry_count > 0 else 0.2,  # ì¬ì‹œë„ ì‹œ ë” ë‚®ì€ temperature
                "top_p": 0.9,
                "num_predict": 8000,  # ë” í° ì‘ë‹µ í—ˆìš©
                "seed": 42 + retry_count  # ì¬ì‹œë„ë§ˆë‹¤ ë‹¤ë¥¸ seed
            }
        }
        
        try:
            print(f"ğŸ¤– Ollama API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {self.model})")
            print(f"ğŸ“¡ ì„œë²„: {self.ollama_url}")
            
            response = requests.post(url, json=payload, timeout=180)  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
            response.raise_for_status()
            
            result = response.json()

            # ì‘ë‹µ í¬ê¸° í™•ì¸
            if "response" in result:
                print(f"   ì‘ë‹µ í¬ê¸°: {len(result['response'])} ë¬¸ì")

            return result
            
        except requests.exceptions.Timeout:
            print(f"â±ï¸  API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ (180ì´ˆ)")
            print("   ëŒ€ìš©ëŸ‰ ëª¨ë¸ì˜ ê²½ìš° ì‘ë‹µ ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return None
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            print(f"   ì„œë²„ ì£¼ì†Œë¥¼ í™•ì¸í•˜ì„¸ìš”: {self.ollama_url}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"   ì‘ë‹µ ì½”ë“œ: {e.response.status_code}")
                print(f"   ì‘ë‹µ ë‚´ìš©: {e.response.text[:200]}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    def parse_evaluation(self, response: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Ollama ì‘ë‹µì—ì„œ í‰ê°€ ê²°ê³¼ íŒŒì‹±

        Args:
            response: Ollama API ì‘ë‹µ

        Returns:
            íŒŒì‹±ëœ í‰ê°€ ê²°ê³¼
        """
        if not response or "response" not in response:
            return None

        # Ollama ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
        evaluation_text = response["response"]

        # í…ìŠ¤íŠ¸ ì •ë¦¬ - ì½”ë“œ ë¸”ë¡ ì œê±°
        evaluation_text = evaluation_text.strip()
        if evaluation_text.startswith('```json'):
            evaluation_text = evaluation_text[7:]
        if evaluation_text.startswith('```'):
            evaluation_text = evaluation_text[3:]
        if evaluation_text.endswith('```'):
            evaluation_text = evaluation_text[:-3]
        evaluation_text = evaluation_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        try:
            evaluation = json.loads(evaluation_text)
            # í•„ìˆ˜ í‚¤ ê²€ì¦
            if "evaluation" in evaluation:
                return evaluation
            else:
                # evaluation í‚¤ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ evaluationìœ¼ë¡œ ê°ì‹¸ê¸°
                return {"evaluation": evaluation}
        except json.JSONDecodeError:
            pass

        # JSONì´ ì˜ë¦° ê²½ìš° ë³µêµ¬ ì‹œë„
        print(f"âš ï¸  ì™„ì „í•œ JSON íŒŒì‹± ì‹¤íŒ¨, ë³µêµ¬ ì‹œë„ ì¤‘...")

        # ì˜ë¦° JSON ë³µêµ¬ í•¨ìˆ˜
        def fix_truncated_json(text):
            import re
            # ì—´ë¦° ê´„í˜¸ì™€ ë‹«íŒ ê´„í˜¸ ìˆ˜ ê³„ì‚°
            open_braces = text.count('{')
            close_braces = text.count('}')
            open_brackets = text.count('[')
            close_brackets = text.count(']')

            # ë¶€ì¡±í•œ ë‹«ëŠ” ê´„í˜¸ ì¶”ê°€
            if open_brackets > close_brackets:
                text += ']' * (open_brackets - close_brackets)
            if open_braces > close_braces:
                text += '}' * (open_braces - close_braces)

            # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
            text = re.sub(r',\s*([\]}])', r'\1', text)

            return text

        # ë³µêµ¬ ì‹œë„
        fixed_text = fix_truncated_json(evaluation_text)

        try:
            evaluation = json.loads(fixed_text)
            print("âœ… ì˜ë¦° JSON ë³µêµ¬ ì„±ê³µ!")

            if "evaluation" in evaluation:
                return evaluation
            else:
                return {"evaluation": evaluation}

        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {evaluation_text[:500] if len(evaluation_text) > 500 else evaluation_text}")

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
        try:
            import re
            # ë” ì •í™•í•œ JSON ì¶”ì¶œ íŒ¨í„´
            json_patterns = [
                r'\{\s*"evaluation"\s*:\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}\s*\}',  # ì¤‘ì²©ëœ evaluation ê°ì²´
                r'\{[^{}]*"total_score"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',  # total_score í¬í•¨ ê°ì²´
            ]

            for pattern in json_patterns:
                json_match = re.search(pattern, evaluation_text, re.DOTALL)
                if json_match:
                    try:
                        extracted = json_match.group()
                        extracted = fix_truncated_json(extracted)
                        evaluation = json.loads(extracted)
                        print("âœ… JSON íŒ¨í„´ ì¶”ì¶œ ì„±ê³µ!")

                        if "evaluation" not in evaluation:
                            return {"evaluation": evaluation}
                        return evaluation
                    except:
                        continue

        except Exception as parse_error:
            print(f"âŒ JSON ì¶”ì¶œ ìµœì¢… ì‹¤íŒ¨: {parse_error}")

        return None

    def evaluate(self, conversation_data: Dict[str, Any], max_retries: int = 3) -> Dict[str, Any]:
        """
        ëŒ€í™” ë‚´ìš© í‰ê°€ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            conversation_data: í‰ê°€í•  ëŒ€í™” ë°ì´í„°
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            í‰ê°€ ê²°ê³¼
        """
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self.test_connection():
            return {"error": "Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨"}
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.create_prompt(conversation_data)
        
        # ì¬ì‹œë„ ë¡œì§
        for retry in range(max_retries):
            print(f"\n{'='*60}")
            if retry == 0:
                print("ğŸš€ í‰ê°€ ì‹œì‘...")
            else:
                print(f"ğŸ”„ ì¬ì‹œë„ {retry}/{max_retries}...")
            print('='*60)
            
            # Ollama API í˜¸ì¶œ
            response = self.call_ollama(prompt, retry_count=retry)
            
            if not response:
                if retry < max_retries - 1:
                    print("â³ 3ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(3)
                    continue
                else:
                    return {"error": "API í˜¸ì¶œ ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)"}
            
            # í‰ê°€ ê²°ê³¼ íŒŒì‹±
            evaluation = self.parse_evaluation(response)
            
            if evaluation:
                print("\n" + "="*60)
                print("âœ… í‰ê°€ ì™„ë£Œ!")
                print("="*60)
                return evaluation
            
            if retry < max_retries - 1:
                print("\nâ³ íŒŒì‹± ì‹¤íŒ¨, 3ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(3)
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        return {
            "error": "í‰ê°€ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)",
            "raw_response": response.get("response", "") if response else ""
        }

    def print_evaluation(self, evaluation: Dict[str, Any]):
        """
        í‰ê°€ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
        
        Args:
            evaluation: í‰ê°€ ê²°ê³¼
        """
        if "error" in evaluation:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {evaluation['error']}")
            if "raw_response" in evaluation:
                print(f"ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {evaluation['raw_response'][:500]}...")
            return
            
        eval_data = evaluation.get("evaluation", evaluation)
        
        print("\n" + "="*60)
        print("ğŸ“Š ë²•ë¥  ìƒë‹´ í’ˆì§ˆ í‰ê°€ ê²°ê³¼")
        print("="*60)
        
        print(f"\nğŸ¯ ì´ì : {eval_data.get('total_score', 'N/A')}/100ì ")
        
        # ê¸ì •ì  ì¸¡ë©´
        print("\nâœ… ê¸ì •ì  ì¸¡ë©´:")
        for aspect in eval_data.get("positive_aspects", []):
            print(f"  â€¢ {aspect['aspect']}: {aspect['description']}")
            print(f"    ê´€ë ¨ ëŒ€í™”: {aspect.get('related_segments', [])}")
        
        # ë¶€ì •ì  ì¸¡ë©´
        print("\nâŒ ê°œì„  í•„ìš” ì¸¡ë©´:")
        for aspect in eval_data.get("negative_aspects", []):
            print(f"  â€¢ {aspect['aspect']}: {aspect['description']}")
            print(f"    ê´€ë ¨ ëŒ€í™”: {aspect.get('related_segments', [])}")
        
        # ê°€ì¥ ì¸ìƒì ì¸ ì 
        impressive = eval_data.get("most_impressive", {})
        if impressive:
            print(f"\nâ­ ê°€ì¥ ì¸ìƒì ì¸ ì :")
            print(f"  {impressive.get('point', 'N/A')}: {impressive.get('description', 'N/A')}")
        
        # ê°œì„  ì œì•ˆ
        print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
        for improvement in eval_data.get("improvements_needed", []):
            print(f"  ëŒ€í™” #{improvement.get('segment_index', 'N/A')}:")
            print(f"    í˜„ì¬: \"{improvement.get('current_response', 'N/A')}\"")
            print(f"    ì œì•ˆ: \"{improvement.get('suggestion', improvement.get('suggested_response', 'N/A'))}\"")
            print(f"    ì´ìœ : {improvement.get('reason', 'N/A')}")
        
        # ì¢…í•© í‰ê°€
        comp_eval = eval_data.get("comprehensive_evaluation", {})
        if comp_eval:
            print("\nğŸ“ˆ ì„¸ë¶€ í‰ê°€:")
            print(f"  â€¢ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥: {comp_eval.get('communication_skill', 'N/A')}ì ")
            print(f"  â€¢ ë²•ë¥  ì „ë¬¸ì„±: {comp_eval.get('legal_expertise', 'N/A')}ì ")
            print(f"  â€¢ ê³ ê° ë§Œì¡±ë„: {comp_eval.get('customer_satisfaction', 'N/A')}ì ")
            print(f"  â€¢ ë¬¸ì œ í•´ê²°ë ¥: {comp_eval.get('problem_solving', 'N/A')}ì ")
            print(f"\nğŸ“ ì´í‰: {comp_eval.get('overall_comment', 'N/A')}")
        
        print("\n" + "="*60)


# í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°
def get_sample_conversation():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ëŒ€í™” ë°ì´í„° ìƒì„±"""
    return {
        "audio_file": "./test_consultation.m4a",
        "duration": 223.9565,
        "processing_time": 30.722412824630737,
        "segments": [
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 0.72,
                "end": 2.72,
                "text": "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ë³€í˜¸ì‚¬ ì‚¬ë¬´ì‹¤ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 2.72,
                "end": 5.72,
                "text": "ì•„, ë„¤. ì € êµí†µì‚¬ê³  ê´€ë ¨í•´ì„œ ìƒë‹´ë°›ê³  ì‹¶ì€ë°ìš”."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 5.72,
                "end": 8.72,
                "text": "ë„¤, êµí†µì‚¬ê³  ìƒë‹´ì´ì‹œêµ°ìš”. ì–¸ì œ ì‚¬ê³ ê°€ ë°œìƒí•˜ì…¨ë‚˜ìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 8.72,
                "end": 11.72,
                "text": "ì–´ì œ ì˜¤í›„ì— ë°œìƒí–ˆëŠ”ë°, ìƒëŒ€ë°©ì´ ì‹ í˜¸ìœ„ë°˜ì„ í–ˆì–´ìš”."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 11.72,
                "end": 15.72,
                "text": "ì•„, ê·¸ëŸ¬ì…¨êµ°ìš”. ê²½ì°° ì‹ ê³ ëŠ” í•˜ì…¨ë‚˜ìš”? ê·¸ë¦¬ê³  ë‹¤ì¹˜ì‹  ê³³ì€ ì—†ìœ¼ì‹ ê°€ìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 15.72,
                "end": 18.72,
                "text": "ë„¤, ê²½ì°° ì‹ ê³ í–ˆê³ ìš”. ëª©ì´ ì¢€ ì•„í”ˆë° ë³‘ì›ì€ ì•„ì§ ì•ˆ ê°”ì–´ìš”."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 18.72,
                "end": 22.72,
                "text": "ì¼ë‹¨ ë³‘ì›ë¶€í„° ê°€ì…”ì•¼ í•  ê²ƒ ê°™ì€ë°ìš”. ì§„ë‹¨ì„œê°€ ìˆì–´ì•¼ ë³´ìƒë°›ê¸° ìˆ˜ì›”í•©ë‹ˆë‹¤."
            },
            {
                "speaker": "ê³ ê°",
                "start": 22.72,
                "end": 25.72,
                "text": "ê·¸ëŸ°ê°€ìš”? ê·¸ëŸ¼ ì–´ëŠ ë³‘ì›ì„ ê°€ì•¼ í•˜ë‚˜ìš”?"
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 25.72,
                "end": 28.72,
                "text": "ê°€ê¹Œìš´ ì •í˜•ì™¸ê³¼ë‚˜ ì‹ ê²½ì™¸ê³¼ ê°€ì‹œë©´ ë©ë‹ˆë‹¤."
            },
            {
                "speaker": "ê³ ê°",
                "start": 28.72,
                "end": 31.72,
                "text": "ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ìƒëŒ€ë°© ë³´í—˜ì‚¬ì—ì„œ ì—°ë½ì´ ì™”ëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 31.72,
                "end": 35.72,
                "text": "ì•„ì§ í•©ì˜í•˜ì§€ ë§ˆì‹œê³ , ì¼ë‹¨ ì¹˜ë£Œë¶€í„° ë°›ìœ¼ì‹  í›„ì— ì €í¬ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
            },
            {
                "speaker": "ê³ ê°",
                "start": 35.72,
                "end": 38.72,
                "text": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì–¸ì œ ë°©ë¬¸í•˜ë©´ ë ê¹Œìš”?"
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 38.72,
                "end": 42.72,
                "text": "ë‚´ì¼ ì˜¤í›„ 2ì‹œë‚˜ 4ì‹œ ì¤‘ì— ê°€ëŠ¥í•˜ì‹  ì‹œê°„ ìˆìœ¼ì‹ ê°€ìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 42.72,
                "end": 44.72,
                "text": "ì˜¤í›„ 2ì‹œì— ê°€ê² ìŠµë‹ˆë‹¤."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 44.72,
                "end": 48.72,
                "text": "ë„¤, ë‚´ì¼ 2ì‹œë¡œ ì˜ˆì•½ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì„±í•¨ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?"
            }
        ]
    }


def load_conversation_from_file(filepath: str) -> Dict[str, Any]:
    """
    JSON íŒŒì¼ì—ì„œ ëŒ€í™” ë°ì´í„° ë¡œë“œ
    
    Args:
        filepath: JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ëŒ€í™” ë°ì´í„°
    """
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None


# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    import argparse
    
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(description='ë²•ë¥  ìƒë‹´ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ')
    parser.add_argument('--host', type=str, default='localhost',
                       help='Ollama ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: localhost)')
    parser.add_argument('--port', type=int, default=11434,
                       help='Ollama ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 11434)')
    parser.add_argument('--file', type=str, default=None,
                       help='í‰ê°€í•  ëŒ€í™” JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', type=str, default='evaluation_result.json',
                       help='ê²°ê³¼ ì €ì¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: evaluation_result.json)')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ›ï¸  ë²•ë¥  ìƒë‹´ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ")
    print("="*60)
    
    # í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    evaluator = LegalConsultationEvaluator(
        ollama_host=args.host,
        ollama_port=args.port
    )
    
    # ëŒ€í™” ë°ì´í„° ë¡œë“œ
    if args.file:
        print(f"\nğŸ“‚ íŒŒì¼ì—ì„œ ëŒ€í™” ë°ì´í„° ë¡œë“œ ì¤‘: {args.file}")
        conversation_data = load_conversation_from_file(args.file)
        if not conversation_data:
            print("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            conversation_data = get_sample_conversation()
    else:
        print("\nğŸ“ ìƒ˜í”Œ ëŒ€í™” ë°ì´í„° ì‚¬ìš©")
        conversation_data = get_sample_conversation()
    
    print(f"âœ… ëŒ€í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
    print(f"   â€¢ ì´ {len(conversation_data.get('segments', []))}ê°œì˜ ëŒ€í™” ì„¸ê·¸ë¨¼íŠ¸")
    print(f"   â€¢ ëŒ€í™” ì‹œê°„: {conversation_data.get('duration', 0):.1f}ì´ˆ")
    
    # í‰ê°€ ì‹¤í–‰
    print("\n" + "="*60)
    print("ğŸ¤– AI í‰ê°€ ì‹œì‘...")
    print("="*60)
    
    start_time = time.time()
    evaluation_result = evaluator.evaluate(conversation_data)
    elapsed_time = time.time() - start_time
    
    if "error" not in evaluation_result:
        print(f"\nâ±ï¸  í‰ê°€ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ)")
    
    # ê²°ê³¼ ì¶œë ¥
    evaluator.print_evaluation(evaluation_result)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    if "error" not in evaluation_result:
        with open(args.output, "w", encoding="utf-8") as f:
            json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ í‰ê°€ ê²°ê³¼ê°€ '{args.output}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"\nâš ï¸  ì˜¤ë¥˜ë¡œ ì¸í•´ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")


# ì‚¬ìš© ì˜ˆì‹œë¥¼ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜
def example_usage():
    """
    ë‹¤ì–‘í•œ ì‚¬ìš© ì˜ˆì‹œ
    """
    # ì˜ˆì‹œ 1: ê¸°ë³¸ ì‚¬ìš©
    evaluator = LegalConsultationEvaluator()
    
    # ì˜ˆì‹œ 2: ì›ê²© ì„œë²„ ì§€ì •
    evaluator = LegalConsultationEvaluator(
        ollama_host="192.168.1.100",  # ì›ê²© ì„œë²„ IP
        ollama_port=11434
    )
    
    # ì˜ˆì‹œ 3: ë„ë©”ì¸ ì´ë¦„ ì‚¬ìš©
    evaluator = LegalConsultationEvaluator(
        ollama_host="ollama.mycompany.com",
        ollama_port=11434
    )
    
    # ëŒ€í™” ë°ì´í„° í‰ê°€
    conversation = get_sample_conversation()
    result = evaluator.evaluate(conversation)
    evaluator.print_evaluation(result)