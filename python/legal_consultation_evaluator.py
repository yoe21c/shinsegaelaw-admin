import json
import requests
from typing import Dict, Any, Optional
import time
import sys

class LegalConsultationEvaluator:
    def __init__(self, ollama_host: str = "localhost", ollama_port: int = 11434):
        """
        ë²•ë¥  ìƒë‹´ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”

        Args:
            ollama_host: Ollama ì„œë²„ í˜¸ìŠ¤íŠ¸ (IP ì£¼ì†Œ ë˜ëŠ” ë„ë©”ì¸)
            ollama_port: Ollama ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 11434)
        """
        self.ollama_url = f"http://{ollama_host}:{ollama_port}"
        self.model = "gpt-oss:20b"
        print(f"ğŸ”— Ollama ì„œë²„ ì„¤ì •: {self.ollama_url}")

        # ì„œë²„ ì´ˆê¸°í™” ì‹œ ì—°ê²° í™•ì¸ (ìµœëŒ€ 10ë¶„ ëŒ€ê¸°)
        if not self.wait_for_server():
            print("âš ï¸  Ollama ì„œë²„ ì—°ê²°ì„ ê±´ë„ˆëœë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„ë©ë‹ˆë‹¤.")

    def wait_for_server(self, max_wait_seconds: int = 600, check_interval: int = 5) -> bool:
        """
        Ollama ì„œë²„ê°€ ì‹¤í–‰ë  ë•Œê¹Œì§€ ëŒ€ê¸°

        Args:
            max_wait_seconds: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - ê¸°ë³¸ê°’: 600ì´ˆ (10ë¶„)
            check_interval: í™•ì¸ ê°„ê²© (ì´ˆ) - ê¸°ë³¸ê°’: 5ì´ˆ

        Returns:
            ì„œë²„ ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        start_time = time.time()
        attempt = 0

        print(f"â³ Ollama ì„œë²„ ì—°ê²° ëŒ€ê¸° ì¤‘... (ìµœëŒ€ {max_wait_seconds}ì´ˆ)")
        print(f"   í™•ì¸ ê°„ê²©: {check_interval}ì´ˆ")

        while time.time() - start_time < max_wait_seconds:
            attempt += 1
            elapsed = int(time.time() - start_time)

            try:
                # API ìƒíƒœ í™•ì¸
                response = requests.get(f"{self.ollama_url}/api/tags", timeout=3)

                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])

                    if models:
                        model_names = [m["name"] for m in models]
                        print(f"\nâœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ! (ì‹œë„ {attempt}íšŒ, {elapsed}ì´ˆ ê²½ê³¼)")
                        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(model_names)}")

                        if self.model in model_names:
                            print(f"âœ… {self.model} ëª¨ë¸ í™•ì¸ë¨!")
                            return True
                        else:
                            print(f"âš ï¸  {self.model} ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                            print(f"   ëª…ë ¹ì–´: ollama run {self.model}")
                    else:
                        print(f"\râ³ [{elapsed}ì´ˆ] ì„œë²„ëŠ” ì‹¤í–‰ ì¤‘ì´ë‚˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤... (ì‹œë„ {attempt}íšŒ)", end="")

                else:
                    print(f"\râ³ [{elapsed}ì´ˆ] ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {response.status_code})... (ì‹œë„ {attempt}íšŒ)", end="")

            except requests.exceptions.Timeout:
                print(f"\râ³ [{elapsed}ì´ˆ] ì—°ê²° ì‹œê°„ ì´ˆê³¼... (ì‹œë„ {attempt}íšŒ)", end="")

            except requests.exceptions.ConnectionError:
                print(f"\râ³ [{elapsed}ì´ˆ] ì„œë²„ ì—°ê²° ëŒ€ê¸° ì¤‘... (ì‹œë„ {attempt}íšŒ)", end="")

            except Exception as e:
                print(f"\râ³ [{elapsed}ì´ˆ] ì˜¤ë¥˜ ë°œìƒ: {str(e)[:50]}... (ì‹œë„ {attempt}íšŒ)", end="")

            # ìµœëŒ€ ì‹œê°„ì— ë„ë‹¬í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ëŒ€ê¸°
            if time.time() - start_time < max_wait_seconds:
                time.sleep(check_interval)

        # íƒ€ì„ì•„ì›ƒ
        elapsed_total = int(time.time() - start_time)
        print(f"\n\nâŒ {elapsed_total}ì´ˆ ë™ì•ˆ ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt}íšŒ)")
        print(f"   ì„œë²„ ì£¼ì†Œ: {self.ollama_url}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   1. Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("   2. ì„œë²„ ì£¼ì†Œì™€ í¬íŠ¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("   3. ë°©í™”ë²½ ì„¤ì • í™•ì¸")
        print("   4. ì›ê²© ì„œë²„ì˜ ê²½ìš°: OLLAMA_HOST=0.0.0.0 ollama serve")
        return False

    def create_prompt(self, conversation_data: Dict[str, Any], evaluation_type: str = "comprehensive") -> str:
        """
        í‰ê°€ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            conversation_data: ëŒ€í™” ë‚´ìš© ë°ì´í„°
            evaluation_type: í‰ê°€ ìœ í˜• (business_potential, expertise, communication, friendliness, comprehensive)

        Returns:
            ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        base_prompt = "ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì£¼ì„ ì—†ì´ JSONë§Œ ì œê³µí•˜ì„¸ìš”.\n\n"

        # í‰ê°€ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸
        if evaluation_type == "business_potential":
            prompt = base_prompt + """ë‹¹ì‹ ì€ ëŒ€í˜• ë¡œíŒì˜ ëŒ€í‘œì…ë‹ˆë‹¤. ë‹¤ìŒ ìƒë‹´ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìˆ˜ì„ ê°€ëŠ¥ì„±ê³¼ ë§¤ì¶œ ê¸°ì—¬ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
1. ê³ ê°ì˜ ì‚¬ê±´ ê·œëª¨ì™€ ë³µì¡ì„±
2. ê³ ê°ì˜ ì§€ë¶ˆ ëŠ¥ë ¥ íŒŒì•… ì—¬ë¶€
3. ìˆ˜ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ìƒë‹´ì‚¬ì˜ ì „ëµ
4. ê³ ê°ì˜ ê¸´ê¸‰ì„±ê³¼ í•„ìš”ì„± íŒŒì•…
5. ê²½ìŸ ë¡œíŒ ëŒ€ë¹„ ì°¨ë³„í™” í¬ì¸íŠ¸ ì œì‹œ

í•„ìˆ˜ JSON êµ¬ì¡°:
{
  "evaluation": {
    "business_score": [0-100 ì ìˆ˜],
    "potential_revenue": "[ì˜ˆìƒ ìˆ˜ì„ë£Œ ë²”ìœ„]",
    "conversion_probability": [0-100 í¼ì„¼íŠ¸],
    "client_profile": {
      "urgency_level": "[ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]",
      "case_complexity": "[ë³µì¡/ë³´í†µ/ë‹¨ìˆœ]",
      "payment_ability": "[ìƒ/ì¤‘/í•˜]",
      "loyalty_potential": "[ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]"
    },
    "consultant_performance": {
      "needs_identification": [0-100],
      "value_proposition": [0-100],
      "closing_technique": [0-100],
      "follow_up_strategy": [0-100]
    },
    "critical_moments": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "moment_type": "[ê¸°íšŒ/ìœ„ê¸°]",
        "description": "[ì„¤ëª…]",
        "impact": "[ê¸ì •ì /ë¶€ì •ì ]"
      }
    ],
    "recommendations": "[ìˆ˜ì„ ì „ëµ ì œì•ˆ]"
  }
}"""

        elif evaluation_type == "expertise":
            prompt = base_prompt + """ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìƒë‹´ì‚¬ì˜ ë²•ë¥  ì „ë¬¸ì„±ì„ ì—„ê²©í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
1. ë²•ë¥  ìš©ì–´ ì‚¬ìš©ì˜ ì •í™•ì„±
2. ê´€ë ¨ ë²•ë ¹ ë° íŒë¡€ ì¸ìš© ì—¬ë¶€
3. ë²•ì  ìŸì  íŒŒì•… ëŠ¥ë ¥
4. í•´ê²° ë°©ì•ˆì˜ êµ¬ì²´ì„±ê³¼ ì‹¤í˜„ ê°€ëŠ¥ì„±
5. ì˜ëª»ëœ ë²•ë¥  ì •ë³´ ì œê³µ ì—¬ë¶€

í•„ìˆ˜ JSON êµ¬ì¡°:
{
  "evaluation": {
    "expertise_score": [0-100 ì ìˆ˜],
    "knowledge_areas": {
      "legal_terminology": [0-100],
      "case_law_knowledge": [0-100],
      "procedural_understanding": [0-100],
      "strategic_thinking": [0-100]
    },
    "professional_indicators": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "indicator_type": "[ì „ë¬¸ì„±/ë¹„ì „ë¬¸ì„±]",
        "description": "[êµ¬ì²´ì  ë‚´ìš©]",
        "severity": "[ì‹¬ê°/ì¤‘ê°„/ê²½ë¯¸]"
      }
    ],
    "legal_errors": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "error_description": "[ì˜¤ë¥˜ ë‚´ìš©]",
        "correct_information": "[ì˜¬ë°”ë¥¸ ì •ë³´]",
        "risk_level": "[ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]"
      }
    ],
    "expertise_gaps": "[ë³´ì™„ í•„ìš” ì˜ì—­]",
    "training_needs": "[êµìœ¡ í•„ìš”ì‚¬í•­]"
  }
}"""

        elif evaluation_type == "communication":
            prompt = base_prompt + """ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ìƒë‹´ì‚¬ì˜ ì˜ì‚¬ì†Œí†µ ëª…í™•ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
1. ë³µì¡í•œ ë²•ë¥  ë‚´ìš©ì˜ ì‰¬ìš´ ì„¤ëª…
2. ê³ ê° ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì  ë‹µë³€
3. ì •ë³´ì˜ êµ¬ì¡°í™”ì™€ ë…¼ë¦¬ì  ì „ë‹¬
4. ê³ ê° ì´í•´ë„ í™•ì¸ ì—¬ë¶€
5. ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ì˜ ëª…í™•ì„±

í•„ìˆ˜ JSON êµ¬ì¡°:
{
  "evaluation": {
    "communication_score": [0-100 ì ìˆ˜],
    "clarity_metrics": {
      "simplification_ability": [0-100],
      "directness": [0-100],
      "structure_logic": [0-100],
      "confirmation_checks": [0-100],
      "action_guidance": [0-100]
    },
    "communication_patterns": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "pattern_type": "[ìš°ìˆ˜/ê°œì„ í•„ìš”]",
        "description": "[êµ¬ì²´ì  ë‚´ìš©]",
        "impact_on_understanding": "[ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]"
      }
    ],
    "jargon_usage": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "term_used": "[ì „ë¬¸ìš©ì–´]",
        "explanation_provided": "[ì˜ˆ/ì•„ë‹ˆì˜¤]",
        "simplification_suggestion": "[ì‰¬ìš´ í‘œí˜„]"
      }
    ],
    "missed_clarifications": "[ë†“ì¹œ ì„¤ëª… ê¸°íšŒ]",
    "communication_improvements": "[ê°œì„  ë°©ì•ˆ]"
  }
}"""

        elif evaluation_type == "friendliness":
            prompt = base_prompt + """ê³ ê° ì„œë¹„ìŠ¤ ê´€ì ì—ì„œ ìƒë‹´ì‚¬ì˜ ì¹œì ˆë„ì™€ ê´€ê³„ êµ¬ì¶• ëŠ¥ë ¥ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
1. ê³µê°ê³¼ ì´í•´ í‘œí˜„
2. ê³ ê° ê°ì • ìƒíƒœ íŒŒì•…ê³¼ ëŒ€ì‘
3. ì ê·¹ì  ê²½ì²­ ìì„¸
4. ì‹ ë¢°ê° í˜•ì„± ë…¸ë ¥
5. ì¥ê¸°ì  ê´€ê³„ êµ¬ì¶• ê°€ëŠ¥ì„±

í•„ìˆ˜ JSON êµ¬ì¡°:
{
  "evaluation": {
    "friendliness_score": [0-100 ì ìˆ˜],
    "relationship_metrics": {
      "empathy_level": [0-100],
      "emotional_intelligence": [0-100],
      "active_listening": [0-100],
      "trust_building": [0-100],
      "warmth_authenticity": [0-100]
    },
    "emotional_moments": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "emotion_type": "[ê³ ê°ê°ì •/ìƒë‹´ì‚¬ëŒ€ì‘]",
        "description": "[êµ¬ì²´ì  ìƒí™©]",
        "response_quality": "[ìš°ìˆ˜/ë³´í†µ/ë¯¸í¡]"
      }
    ],
    "rapport_indicators": [
      {
        "segment_index": [ì¸ë±ìŠ¤],
        "indicator": "[ì§€í‘œ ë‚´ìš©]",
        "strength": "[ê°•í•¨/ì¤‘ê°„/ì•½í•¨]"
      }
    ],
    "relationship_potential": "[ì¥ê¸° ê´€ê³„ ê°€ëŠ¥ì„± í‰ê°€]",
    "customer_retention_likelihood": [0-100]
  }
}"""

        else:  # comprehensive (ê¸°ë³¸ê°’)
            prompt = base_prompt + """ë¡œíŒ ëŒ€í‘œ ê´€ì ì—ì„œ ì „ì²´ì ì¸ ìƒë‹´ í’ˆì§ˆì„ ì¢…í•© í‰ê°€í•´ì£¼ì„¸ìš”.

í•„ìˆ˜ JSON êµ¬ì¡°:
{
  "evaluation": {
    "total_score": [0-100],
    "summary_scores": {
      "business_potential": [0-100],
      "legal_expertise": [0-100],
      "communication_clarity": [0-100],
      "customer_friendliness": [0-100]
    },
    "executive_summary": "[ëŒ€í‘œ ë³´ê³ ìš© í•µì‹¬ ìš”ì•½]",
    "strengths": ["[ê°•ì 1]", "[ê°•ì 2]"],
    "weaknesses": ["[ì•½ì 1]", "[ì•½ì 2]"],
    "action_items": ["[ì¡°ì¹˜ì‚¬í•­1]", "[ì¡°ì¹˜ì‚¬í•­2]"],
    "consultant_rating": "[S/A/B/C/D ë“±ê¸‰]"
  }
}"""

        prompt += "\n\nëŒ€í™” ë°ì´í„°:\n"
        conversation_str = json.dumps(conversation_data, ensure_ascii=False, indent=2)
        return prompt + conversation_str

    def test_connection(self) -> bool:
        """
        Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        
        Returns:
            ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                
                print(f"âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ!")
                print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(model_names) if model_names else 'ì—†ìŒ'}")
                
                if self.model in model_names:
                    print(f"âœ… {self.model} ëª¨ë¸ í™•ì¸ë¨!")
                    return True
                else:
                    print(f"âš ï¸  {self.model} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    if model_names:
                        print(f"   ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ self.model ê°’ì„ ë³€ê²½í•˜ì„¸ìš”.")
                    else:
                        print(f"   ì›ê²© ì„œë²„ì—ì„œ 'ollama run {self.model}' ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
                    return False
            else:
                print(f"âŒ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False
                
        except requests.exceptions.Timeout:
            print(f"â±ï¸  ì—°ê²° ì‹œê°„ ì´ˆê³¼. ì„œë²„ ì£¼ì†Œë¥¼ í™•ì¸í•˜ì„¸ìš”: {self.ollama_url}")
            return False
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.ollama_url}")
            print(f"   ì˜¤ë¥˜: {str(e)}")
            print("\nğŸ’¡ í™•ì¸ì‚¬í•­:")
            print("   1. ì›ê²© ì„œë²„ì—ì„œ Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
            print("   2. ë°©í™”ë²½ ì„¤ì • í™•ì¸ (í¬íŠ¸ 11434)")
            print("   3. ì›ê²© ì„œë²„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ Ollama ì‹¤í–‰:")
            print("      OLLAMA_HOST=0.0.0.0 ollama serve")
            return False
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False

    def call_ollama(self, prompt: str, retry_count: int = 0) -> Optional[Dict[str, Any]]:
        """
        Ollama API í˜¸ì¶œ

        Args:
            prompt: í‰ê°€ í”„ë¡¬í”„íŠ¸
            retry_count: í˜„ì¬ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            API ì‘ë‹µ ê²°ê³¼
        """
        url = f"{self.ollama_url}/api/generate"
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1 if retry_count > 0 else 0.2,  # ì¬ì‹œë„ ì‹œ ë” ë‚®ì€ temperature
                "top_p": 0.9,
                "num_predict": 8000,  # ë” í° ì‘ë‹µ í—ˆìš©
                "seed": 42 + retry_count  # ì¬ì‹œë„ë§ˆë‹¤ ë‹¤ë¥¸ seed
            }
        }
        
        try:
            print(f"ğŸ¤– Ollama API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {self.model})")
            print(f"ğŸ“¡ ì„œë²„: {self.ollama_url}")
            
            response = requests.post(url, json=payload, timeout=180)  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
            response.raise_for_status()
            
            result = response.json()

            # ì‘ë‹µ í¬ê¸° í™•ì¸
            if "response" in result:
                print(f"   ì‘ë‹µ í¬ê¸°: {len(result['response'])} ë¬¸ì")

            return result
            
        except requests.exceptions.Timeout:
            print(f"â±ï¸  API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ (180ì´ˆ)")
            print("   ëŒ€ìš©ëŸ‰ ëª¨ë¸ì˜ ê²½ìš° ì‘ë‹µ ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return None
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            print(f"   ì„œë²„ ì£¼ì†Œë¥¼ í™•ì¸í•˜ì„¸ìš”: {self.ollama_url}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"   ì‘ë‹µ ì½”ë“œ: {e.response.status_code}")
                print(f"   ì‘ë‹µ ë‚´ìš©: {e.response.text[:200]}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    def parse_evaluation(self, response: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Ollama ì‘ë‹µì—ì„œ í‰ê°€ ê²°ê³¼ íŒŒì‹±

        Args:
            response: Ollama API ì‘ë‹µ

        Returns:
            íŒŒì‹±ëœ í‰ê°€ ê²°ê³¼
        """
        if not response or "response" not in response:
            return None

        # Ollama ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
        evaluation_text = response["response"]

        # í…ìŠ¤íŠ¸ ì •ë¦¬ - ì½”ë“œ ë¸”ë¡ ì œê±°
        evaluation_text = evaluation_text.strip()
        if evaluation_text.startswith('```json'):
            evaluation_text = evaluation_text[7:]
        if evaluation_text.startswith('```'):
            evaluation_text = evaluation_text[3:]
        if evaluation_text.endswith('```'):
            evaluation_text = evaluation_text[:-3]
        evaluation_text = evaluation_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        try:
            evaluation = json.loads(evaluation_text)
            # í•„ìˆ˜ í‚¤ ê²€ì¦
            if "evaluation" in evaluation:
                return evaluation
            else:
                # evaluation í‚¤ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ evaluationìœ¼ë¡œ ê°ì‹¸ê¸°
                return {"evaluation": evaluation}
        except json.JSONDecodeError:
            pass

        # JSONì´ ì˜ë¦° ê²½ìš° ë³µêµ¬ ì‹œë„
        print(f"âš ï¸  ì™„ì „í•œ JSON íŒŒì‹± ì‹¤íŒ¨, ë³µêµ¬ ì‹œë„ ì¤‘...")

        # ì˜ë¦° JSON ë³µêµ¬ í•¨ìˆ˜
        def fix_truncated_json(text):
            import re
            # ì—´ë¦° ê´„í˜¸ì™€ ë‹«íŒ ê´„í˜¸ ìˆ˜ ê³„ì‚°
            open_braces = text.count('{')
            close_braces = text.count('}')
            open_brackets = text.count('[')
            close_brackets = text.count(']')

            # ë¶€ì¡±í•œ ë‹«ëŠ” ê´„í˜¸ ì¶”ê°€
            if open_brackets > close_brackets:
                text += ']' * (open_brackets - close_brackets)
            if open_braces > close_braces:
                text += '}' * (open_braces - close_braces)

            # ë§ˆì§€ë§‰ ì½¤ë§ˆ ì œê±°
            text = re.sub(r',\s*([\]}])', r'\1', text)

            return text

        # ë³µêµ¬ ì‹œë„
        fixed_text = fix_truncated_json(evaluation_text)

        try:
            evaluation = json.loads(fixed_text)
            print("âœ… ì˜ë¦° JSON ë³µêµ¬ ì„±ê³µ!")

            if "evaluation" in evaluation:
                return evaluation
            else:
                return {"evaluation": evaluation}

        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {evaluation_text[:500] if len(evaluation_text) > 500 else evaluation_text}")

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
        try:
            import re
            # ë” ì •í™•í•œ JSON ì¶”ì¶œ íŒ¨í„´
            json_patterns = [
                r'\{\s*"evaluation"\s*:\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}\s*\}',  # ì¤‘ì²©ëœ evaluation ê°ì²´
                r'\{[^{}]*"total_score"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',  # total_score í¬í•¨ ê°ì²´
            ]

            for pattern in json_patterns:
                json_match = re.search(pattern, evaluation_text, re.DOTALL)
                if json_match:
                    try:
                        extracted = json_match.group()
                        extracted = fix_truncated_json(extracted)
                        evaluation = json.loads(extracted)
                        print("âœ… JSON íŒ¨í„´ ì¶”ì¶œ ì„±ê³µ!")

                        if "evaluation" not in evaluation:
                            return {"evaluation": evaluation}
                        return evaluation
                    except:
                        continue

        except Exception as parse_error:
            print(f"âŒ JSON ì¶”ì¶œ ìµœì¢… ì‹¤íŒ¨: {parse_error}")

        return None

    def evaluate(self, conversation_data: Dict[str, Any], max_retries: int = 3) -> Dict[str, Any]:
        """
        ëŒ€í™” ë‚´ìš© í‰ê°€ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

        Args:
            conversation_data: í‰ê°€í•  ëŒ€í™” ë°ì´í„°
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            í‰ê°€ ê²°ê³¼
        """
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self.test_connection():
            return {"error": "Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨"}

        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ì¢…í•© í‰ê°€)
        prompt = self.create_prompt(conversation_data, "comprehensive")

        # ì¬ì‹œë„ ë¡œì§
        for retry in range(max_retries):
            print(f"\n{'='*60}")
            if retry == 0:
                print("ğŸš€ í‰ê°€ ì‹œì‘...")
            else:
                print(f"ğŸ”„ ì¬ì‹œë„ {retry}/{max_retries}...")
            print('='*60)

            # Ollama API í˜¸ì¶œ
            response = self.call_ollama(prompt, retry_count=retry)

            if not response:
                if retry < max_retries - 1:
                    print("â³ 3ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(3)
                    continue
                else:
                    return {"error": "API í˜¸ì¶œ ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)"}

            # í‰ê°€ ê²°ê³¼ íŒŒì‹±
            evaluation = self.parse_evaluation(response)

            if evaluation:
                print("\n" + "="*60)
                print("âœ… í‰ê°€ ì™„ë£Œ!")
                print("="*60)
                return evaluation

            if retry < max_retries - 1:
                print("\nâ³ íŒŒì‹± ì‹¤íŒ¨, 3ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(3)

        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        return {
            "error": "í‰ê°€ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)",
            "raw_response": response.get("response", "") if response else ""
        }

    def evaluate_detailed(self, conversation_data: Dict[str, Any], max_retries: int = 2) -> Dict[str, Any]:
        """
        4ê°€ì§€ í•µì‹¬ ì˜ì—­ë³„ ìƒì„¸ í‰ê°€ ì‹¤í–‰

        Args:
            conversation_data: í‰ê°€í•  ëŒ€í™” ë°ì´í„°
            max_retries: ê° í‰ê°€ë³„ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            í†µí•© í‰ê°€ ê²°ê³¼
        """
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self.test_connection():
            return {"error": "Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨"}

        evaluation_types = [
            ("business_potential", "ğŸ’¼ ìˆ˜ì„ ê°€ëŠ¥ì„± ë° ë§¤ì¶œ í‰ê°€"),
            ("expertise", "ğŸ“ ë²•ë¥  ì „ë¬¸ì„± í‰ê°€"),
            ("communication", "ğŸ’¬ ëª…í™•í•œ ì˜ì‚¬ì†Œí†µ í‰ê°€"),
            ("friendliness", "ğŸ¤ ì¹œì ˆë„ ë° ê´€ê³„ êµ¬ì¶• í‰ê°€")
        ]

        detailed_results = {}

        for eval_type, eval_name in evaluation_types:
            print(f"\n{'='*70}")
            print(f"{eval_name}")
            print('='*70)

            # ê° í‰ê°€ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_prompt(conversation_data, eval_type)

            # ì¬ì‹œë„ ë¡œì§
            for retry in range(max_retries):
                if retry > 0:
                    print(f"ğŸ”„ ì¬ì‹œë„ {retry}/{max_retries}...")

                # Ollama API í˜¸ì¶œ
                response = self.call_ollama(prompt, retry_count=retry)

                if not response:
                    if retry < max_retries - 1:
                        print("â³ 3ì´ˆ í›„ ì¬ì‹œë„...")
                        time.sleep(3)
                        continue
                    else:
                        detailed_results[eval_type] = {"error": "API í˜¸ì¶œ ì‹¤íŒ¨"}
                        break

                # í‰ê°€ ê²°ê³¼ íŒŒì‹±
                evaluation = self.parse_evaluation(response)

                if evaluation:
                    print(f"âœ… {eval_name} ì™„ë£Œ!")
                    detailed_results[eval_type] = evaluation.get("evaluation", evaluation)
                    break

                if retry < max_retries - 1:
                    print("â³ íŒŒì‹± ì‹¤íŒ¨, 3ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(3)
                else:
                    detailed_results[eval_type] = {"error": "í‰ê°€ íŒŒì‹± ì‹¤íŒ¨"}

            # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
            time.sleep(2)

        # ì¢…í•© í‰ê°€ ì‹¤í–‰
        print(f"\n{'='*70}")
        print("ğŸ“Š ì¢…í•© í‰ê°€")
        print('='*70)

        comprehensive_prompt = self.create_prompt(conversation_data, "comprehensive")
        comprehensive_result = None

        for retry in range(max_retries):
            if retry > 0:
                print(f"ğŸ”„ ì¬ì‹œë„ {retry}/{max_retries}...")

            response = self.call_ollama(comprehensive_prompt, retry_count=retry)

            if response:
                evaluation = self.parse_evaluation(response)
                if evaluation:
                    comprehensive_result = evaluation.get("evaluation", evaluation)
                    print("âœ… ì¢…í•© í‰ê°€ ì™„ë£Œ!")
                    break

            if retry < max_retries - 1:
                time.sleep(3)

        # ìµœì¢… ê²°ê³¼ í†µí•©
        return {
            "detailed_evaluations": detailed_results,
            "comprehensive_evaluation": comprehensive_result or {"error": "ì¢…í•© í‰ê°€ ì‹¤íŒ¨"},
            "evaluation_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "conversation_info": {
                "duration": conversation_data.get("duration", 0),
                "segments_count": len(conversation_data.get("segments", []))
            }
        }

    def print_evaluation(self, evaluation: Dict[str, Any]):
        """
        í‰ê°€ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥

        Args:
            evaluation: í‰ê°€ ê²°ê³¼
        """
        if "error" in evaluation:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {evaluation['error']}")
            if "raw_response" in evaluation:
                print(f"ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {evaluation['raw_response'][:500]}...")
            return

        eval_data = evaluation.get("evaluation", evaluation)

        print("\n" + "="*60)
        print("ğŸ“Š ë²•ë¥  ìƒë‹´ í’ˆì§ˆ í‰ê°€ ê²°ê³¼")
        print("="*60)

        print(f"\nğŸ¯ ì´ì : {eval_data.get('total_score', 'N/A')}/100ì ")

        # ê¸ì •ì  ì¸¡ë©´
        print("\nâœ… ê¸ì •ì  ì¸¡ë©´:")
        for aspect in eval_data.get("positive_aspects", []):
            print(f"  â€¢ {aspect['aspect']}: {aspect['description']}")
            print(f"    ê´€ë ¨ ëŒ€í™”: {aspect.get('related_segments', [])}")

        # ë¶€ì •ì  ì¸¡ë©´
        print("\nâŒ ê°œì„  í•„ìš” ì¸¡ë©´:")
        for aspect in eval_data.get("negative_aspects", []):
            print(f"  â€¢ {aspect['aspect']}: {aspect['description']}")
            print(f"    ê´€ë ¨ ëŒ€í™”: {aspect.get('related_segments', [])}")

        # ê°€ì¥ ì¸ìƒì ì¸ ì 
        impressive = eval_data.get("most_impressive", {})
        if impressive:
            print(f"\nâ­ ê°€ì¥ ì¸ìƒì ì¸ ì :")
            print(f"  {impressive.get('point', 'N/A')}: {impressive.get('description', 'N/A')}")

        # ê°œì„  ì œì•ˆ
        print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
        for improvement in eval_data.get("improvements_needed", []):
            print(f"  ëŒ€í™” #{improvement.get('segment_index', 'N/A')}:")
            print(f"    í˜„ì¬: \"{improvement.get('current_response', 'N/A')}\"")
            print(f"    ì œì•ˆ: \"{improvement.get('suggestion', improvement.get('suggested_response', 'N/A'))}\"")
            print(f"    ì´ìœ : {improvement.get('reason', 'N/A')}")

        # ì¢…í•© í‰ê°€
        comp_eval = eval_data.get("comprehensive_evaluation", {})
        if comp_eval:
            print("\nğŸ“ˆ ì„¸ë¶€ í‰ê°€:")
            print(f"  â€¢ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥: {comp_eval.get('communication_skill', 'N/A')}ì ")
            print(f"  â€¢ ë²•ë¥  ì „ë¬¸ì„±: {comp_eval.get('legal_expertise', 'N/A')}ì ")
            print(f"  â€¢ ê³ ê° ë§Œì¡±ë„: {comp_eval.get('customer_satisfaction', 'N/A')}ì ")
            print(f"  â€¢ ë¬¸ì œ í•´ê²°ë ¥: {comp_eval.get('problem_solving', 'N/A')}ì ")
            print(f"\nğŸ“ ì´í‰: {comp_eval.get('overall_comment', 'N/A')}")

        print("\n" + "="*60)

    def print_detailed_evaluation(self, evaluation: Dict[str, Any]):
        """
        ìƒì„¸ í‰ê°€ ê²°ê³¼ë¥¼ ë¡œíŒ ëŒ€í‘œë¥¼ ìœ„í•´ ì¶œë ¥

        Args:
            evaluation: ìƒì„¸ í‰ê°€ ê²°ê³¼
        """
        if "error" in evaluation:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {evaluation['error']}")
            return

        print("\n" + "="*80)
        print("ğŸ¢ ë¡œíŒ ëŒ€í‘œ ë³´ê³ ì„œ - ìƒë‹´ í’ˆì§ˆ ìƒì„¸ í‰ê°€")
        print("="*80)

        # ìƒë‹´ ì •ë³´
        info = evaluation.get("conversation_info", {})
        print(f"\nğŸ“‹ ìƒë‹´ ì •ë³´:")
        print(f"  â€¢ ìƒë‹´ ì‹œê°„: {info.get('duration', 0):.1f}ì´ˆ")
        print(f"  â€¢ ëŒ€í™” ìˆ˜: {info.get('segments_count', 0)}ê°œ")
        print(f"  â€¢ í‰ê°€ ì¼ì‹œ: {evaluation.get('evaluation_timestamp', 'N/A')}")

        detailed = evaluation.get("detailed_evaluations", {})

        # 1. ìˆ˜ì„ ê°€ëŠ¥ì„± í‰ê°€
        if "business_potential" in detailed:
            business = detailed["business_potential"]
            if "error" not in business:
                print(f"\n{'='*80}")
                print("ğŸ’¼ 1. ìˆ˜ì„ ê°€ëŠ¥ì„± ë° ë§¤ì¶œ í‰ê°€")
                print("-"*80)
                print(f"  ğŸ“Š ë¹„ì¦ˆë‹ˆìŠ¤ ì ìˆ˜: {business.get('business_score', 'N/A')}/100ì ")
                print(f"  ğŸ’° ì˜ˆìƒ ìˆ˜ì„ë£Œ: {business.get('potential_revenue', 'N/A')}")
                print(f"  ğŸ“ˆ ìˆ˜ì„ í™•ë¥ : {business.get('conversion_probability', 'N/A')}%")

                profile = business.get("client_profile", {})
                if profile:
                    print(f"\n  ê³ ê° í”„ë¡œí•„:")
                    print(f"    â€¢ ê¸´ê¸‰ì„±: {profile.get('urgency_level', 'N/A')}")
                    print(f"    â€¢ ì‚¬ê±´ ë³µì¡ë„: {profile.get('case_complexity', 'N/A')}")
                    print(f"    â€¢ ì§€ë¶ˆ ëŠ¥ë ¥: {profile.get('payment_ability', 'N/A')}")
                    print(f"    â€¢ ì¶©ì„±ë„ ê°€ëŠ¥ì„±: {profile.get('loyalty_potential', 'N/A')}")

                perf = business.get("consultant_performance", {})
                if perf:
                    print(f"\n  ìƒë‹´ì‚¬ ì˜ì—… ì„±ê³¼:")
                    print(f"    â€¢ ë‹ˆì¦ˆ íŒŒì•…: {perf.get('needs_identification', 'N/A')}/100")
                    print(f"    â€¢ ê°€ì¹˜ ì œì•ˆ: {perf.get('value_proposition', 'N/A')}/100")
                    print(f"    â€¢ í´ë¡œì§• ê¸°ë²•: {perf.get('closing_technique', 'N/A')}/100")
                    print(f"    â€¢ í›„ì† ì „ëµ: {perf.get('follow_up_strategy', 'N/A')}/100")

                if business.get("recommendations"):
                    print(f"\n  ğŸ’¡ ìˆ˜ì„ ì „ëµ ì œì•ˆ:")
                    print(f"    {business['recommendations']}")

        # 2. ì „ë¬¸ì„± í‰ê°€
        if "expertise" in detailed:
            expertise = detailed["expertise"]
            if "error" not in expertise:
                print(f"\n{'='*80}")
                print("ğŸ“ 2. ë²•ë¥  ì „ë¬¸ì„± í‰ê°€")
                print("-"*80)
                print(f"  ğŸ“Š ì „ë¬¸ì„± ì ìˆ˜: {expertise.get('expertise_score', 'N/A')}/100ì ")

                knowledge = expertise.get("knowledge_areas", {})
                if knowledge:
                    print(f"\n  ì§€ì‹ ì˜ì—­ í‰ê°€:")
                    print(f"    â€¢ ë²•ë¥  ìš©ì–´: {knowledge.get('legal_terminology', 'N/A')}/100")
                    print(f"    â€¢ íŒë¡€ ì§€ì‹: {knowledge.get('case_law_knowledge', 'N/A')}/100")
                    print(f"    â€¢ ì ˆì°¨ ì´í•´: {knowledge.get('procedural_understanding', 'N/A')}/100")
                    print(f"    â€¢ ì „ëµì  ì‚¬ê³ : {knowledge.get('strategic_thinking', 'N/A')}/100")

                errors = expertise.get("legal_errors", [])
                if errors:
                    print(f"\n  âš ï¸ ë²•ë¥  ì˜¤ë¥˜ ë°œê²¬:")
                    for error in errors[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                        print(f"    â€¢ ëŒ€í™” #{error.get('segment_index', 'N/A')}: {error.get('error_description', 'N/A')}")
                        print(f"      ìœ„í—˜ë„: {error.get('risk_level', 'N/A')}")

                if expertise.get("training_needs"):
                    print(f"\n  ğŸ“š êµìœ¡ í•„ìš”ì‚¬í•­:")
                    print(f"    {expertise['training_needs']}")

        # 3. ì˜ì‚¬ì†Œí†µ í‰ê°€
        if "communication" in detailed:
            comm = detailed["communication"]
            if "error" not in comm:
                print(f"\n{'='*80}")
                print("ğŸ’¬ 3. ëª…í™•í•œ ì˜ì‚¬ì†Œí†µ í‰ê°€")
                print("-"*80)
                print(f"  ğŸ“Š ì˜ì‚¬ì†Œí†µ ì ìˆ˜: {comm.get('communication_score', 'N/A')}/100ì ")

                clarity = comm.get("clarity_metrics", {})
                if clarity:
                    print(f"\n  ëª…í™•ì„± ì§€í‘œ:")
                    print(f"    â€¢ ë‹¨ìˆœí™” ëŠ¥ë ¥: {clarity.get('simplification_ability', 'N/A')}/100")
                    print(f"    â€¢ ì§ì ‘ì„±: {clarity.get('directness', 'N/A')}/100")
                    print(f"    â€¢ ë…¼ë¦¬ êµ¬ì¡°: {clarity.get('structure_logic', 'N/A')}/100")
                    print(f"    â€¢ í™•ì¸ ì²´í¬: {clarity.get('confirmation_checks', 'N/A')}/100")
                    print(f"    â€¢ í–‰ë™ ì•ˆë‚´: {clarity.get('action_guidance', 'N/A')}/100")

                if comm.get("communication_improvements"):
                    print(f"\n  ğŸ’¡ ì˜ì‚¬ì†Œí†µ ê°œì„  ë°©ì•ˆ:")
                    print(f"    {comm['communication_improvements']}")

        # 4. ì¹œì ˆë„ í‰ê°€
        if "friendliness" in detailed:
            friend = detailed["friendliness"]
            if "error" not in friend:
                print(f"\n{'='*80}")
                print("ğŸ¤ 4. ì¹œì ˆë„ ë° ê´€ê³„ êµ¬ì¶• í‰ê°€")
                print("-"*80)
                print(f"  ğŸ“Š ì¹œì ˆë„ ì ìˆ˜: {friend.get('friendliness_score', 'N/A')}/100ì ")
                print(f"  ğŸ”„ ê³ ê° ìœ ì§€ ê°€ëŠ¥ì„±: {friend.get('customer_retention_likelihood', 'N/A')}%")

                relation = friend.get("relationship_metrics", {})
                if relation:
                    print(f"\n  ê´€ê³„ ì§€í‘œ:")
                    print(f"    â€¢ ê³µê° ìˆ˜ì¤€: {relation.get('empathy_level', 'N/A')}/100")
                    print(f"    â€¢ ê°ì • ì§€ëŠ¥: {relation.get('emotional_intelligence', 'N/A')}/100")
                    print(f"    â€¢ ì ê·¹ì  ê²½ì²­: {relation.get('active_listening', 'N/A')}/100")
                    print(f"    â€¢ ì‹ ë¢° êµ¬ì¶•: {relation.get('trust_building', 'N/A')}/100")
                    print(f"    â€¢ ë”°ëœ»í•¨/ì§„ì •ì„±: {relation.get('warmth_authenticity', 'N/A')}/100")

                if friend.get("relationship_potential"):
                    print(f"\n  ğŸ’¡ ì¥ê¸° ê´€ê³„ í‰ê°€:")
                    print(f"    {friend['relationship_potential']}")

        # ì¢…í•© í‰ê°€
        comprehensive = evaluation.get("comprehensive_evaluation", {})
        if comprehensive and "error" not in comprehensive:
            print(f"\n{'='*80}")
            print("ğŸ“Š ì¢…í•© í‰ê°€")
            print("-"*80)

            scores = comprehensive.get("summary_scores", {})
            if scores:
                print(f"\n  í•µì‹¬ ì ìˆ˜:")
                print(f"    â€¢ ìˆ˜ì„ ê°€ëŠ¥ì„±: {scores.get('business_potential', 'N/A')}/100")
                print(f"    â€¢ ë²•ë¥  ì „ë¬¸ì„±: {scores.get('legal_expertise', 'N/A')}/100")
                print(f"    â€¢ ì˜ì‚¬ì†Œí†µ: {scores.get('communication_clarity', 'N/A')}/100")
                print(f"    â€¢ ê³ ê° ì¹œí™”: {scores.get('customer_friendliness', 'N/A')}/100")

            print(f"\n  ğŸ† ìƒë‹´ì‚¬ ë“±ê¸‰: {comprehensive.get('consultant_rating', 'N/A')}")
            print(f"\n  ğŸ’¼ ëŒ€í‘œ ë³´ê³  ìš”ì•½:")
            print(f"    {comprehensive.get('executive_summary', 'N/A')}")

            if comprehensive.get("action_items"):
                print(f"\n  âš¡ ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­:")
                for item in comprehensive.get("action_items", []):
                    print(f"    â€¢ {item}")

        print("\n" + "="*80)
        print("ë³´ê³ ì„œ ë")
        print("="*80)


# í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°
def get_sample_conversation():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ëŒ€í™” ë°ì´í„° ìƒì„±"""
    return {
        "audio_file": "./test_consultation.m4a",
        "duration": 223.9565,
        "processing_time": 30.722412824630737,
        "segments": [
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 0.72,
                "end": 2.72,
                "text": "ì•ˆë…•í•˜ì„¸ìš”, ê¹€ë³€í˜¸ì‚¬ ì‚¬ë¬´ì‹¤ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 2.72,
                "end": 5.72,
                "text": "ì•„, ë„¤. ì € êµí†µì‚¬ê³  ê´€ë ¨í•´ì„œ ìƒë‹´ë°›ê³  ì‹¶ì€ë°ìš”."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 5.72,
                "end": 8.72,
                "text": "ë„¤, êµí†µì‚¬ê³  ìƒë‹´ì´ì‹œêµ°ìš”. ì–¸ì œ ì‚¬ê³ ê°€ ë°œìƒí•˜ì…¨ë‚˜ìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 8.72,
                "end": 11.72,
                "text": "ì–´ì œ ì˜¤í›„ì— ë°œìƒí–ˆëŠ”ë°, ìƒëŒ€ë°©ì´ ì‹ í˜¸ìœ„ë°˜ì„ í–ˆì–´ìš”."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 11.72,
                "end": 15.72,
                "text": "ì•„, ê·¸ëŸ¬ì…¨êµ°ìš”. ê²½ì°° ì‹ ê³ ëŠ” í•˜ì…¨ë‚˜ìš”? ê·¸ë¦¬ê³  ë‹¤ì¹˜ì‹  ê³³ì€ ì—†ìœ¼ì‹ ê°€ìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 15.72,
                "end": 18.72,
                "text": "ë„¤, ê²½ì°° ì‹ ê³ í–ˆê³ ìš”. ëª©ì´ ì¢€ ì•„í”ˆë° ë³‘ì›ì€ ì•„ì§ ì•ˆ ê°”ì–´ìš”."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 18.72,
                "end": 22.72,
                "text": "ì¼ë‹¨ ë³‘ì›ë¶€í„° ê°€ì…”ì•¼ í•  ê²ƒ ê°™ì€ë°ìš”. ì§„ë‹¨ì„œê°€ ìˆì–´ì•¼ ë³´ìƒë°›ê¸° ìˆ˜ì›”í•©ë‹ˆë‹¤."
            },
            {
                "speaker": "ê³ ê°",
                "start": 22.72,
                "end": 25.72,
                "text": "ê·¸ëŸ°ê°€ìš”? ê·¸ëŸ¼ ì–´ëŠ ë³‘ì›ì„ ê°€ì•¼ í•˜ë‚˜ìš”?"
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 25.72,
                "end": 28.72,
                "text": "ê°€ê¹Œìš´ ì •í˜•ì™¸ê³¼ë‚˜ ì‹ ê²½ì™¸ê³¼ ê°€ì‹œë©´ ë©ë‹ˆë‹¤."
            },
            {
                "speaker": "ê³ ê°",
                "start": 28.72,
                "end": 31.72,
                "text": "ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ìƒëŒ€ë°© ë³´í—˜ì‚¬ì—ì„œ ì—°ë½ì´ ì™”ëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 31.72,
                "end": 35.72,
                "text": "ì•„ì§ í•©ì˜í•˜ì§€ ë§ˆì‹œê³ , ì¼ë‹¨ ì¹˜ë£Œë¶€í„° ë°›ìœ¼ì‹  í›„ì— ì €í¬ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
            },
            {
                "speaker": "ê³ ê°",
                "start": 35.72,
                "end": 38.72,
                "text": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì–¸ì œ ë°©ë¬¸í•˜ë©´ ë ê¹Œìš”?"
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 38.72,
                "end": 42.72,
                "text": "ë‚´ì¼ ì˜¤í›„ 2ì‹œë‚˜ 4ì‹œ ì¤‘ì— ê°€ëŠ¥í•˜ì‹  ì‹œê°„ ìˆìœ¼ì‹ ê°€ìš”?"
            },
            {
                "speaker": "ê³ ê°",
                "start": 42.72,
                "end": 44.72,
                "text": "ì˜¤í›„ 2ì‹œì— ê°€ê² ìŠµë‹ˆë‹¤."
            },
            {
                "speaker": "ìƒë‹´ì‚¬",
                "start": 44.72,
                "end": 48.72,
                "text": "ë„¤, ë‚´ì¼ 2ì‹œë¡œ ì˜ˆì•½ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì„±í•¨ì´ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?"
            }
        ]
    }


def load_conversation_from_file(filepath: str) -> Dict[str, Any]:
    """
    JSON íŒŒì¼ì—ì„œ ëŒ€í™” ë°ì´í„° ë¡œë“œ
    
    Args:
        filepath: JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ëŒ€í™” ë°ì´í„°
    """
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None


# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    import argparse

    # ëª…ë ¹ì¤„ ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(description='ë²•ë¥  ìƒë‹´ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ')
    parser.add_argument('--host', type=str, default='localhost',
                       help='Ollama ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: localhost)')
    parser.add_argument('--port', type=int, default=11434,
                       help='Ollama ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 11434)')
    parser.add_argument('--file', type=str, default=None,
                       help='í‰ê°€í•  ëŒ€í™” JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', type=str, default='evaluation_result.json',
                       help='ê²°ê³¼ ì €ì¥ íŒŒì¼ëª… (ê¸°ë³¸ê°’: evaluation_result.json)')
    parser.add_argument('--mode', type=str, default='detailed',
                       choices=['simple', 'detailed'],
                       help='í‰ê°€ ëª¨ë“œ - simple: ê°„ë‹¨í‰ê°€, detailed: ìƒì„¸í‰ê°€ (ê¸°ë³¸ê°’: detailed)')

    args = parser.parse_args()

    print("="*80)
    print("ğŸ›ï¸  ë²•ë¥  ìƒë‹´ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ - ë¡œíŒ ëŒ€í‘œìš©")
    print("="*80)

    # í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    evaluator = LegalConsultationEvaluator(
        ollama_host=args.host,
        ollama_port=args.port
    )

    # ëŒ€í™” ë°ì´í„° ë¡œë“œ
    if args.file:
        print(f"\nğŸ“‚ íŒŒì¼ì—ì„œ ëŒ€í™” ë°ì´í„° ë¡œë“œ ì¤‘: {args.file}")
        conversation_data = load_conversation_from_file(args.file)
        if not conversation_data:
            print("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            conversation_data = get_sample_conversation()
    else:
        print("\nğŸ“ ìƒ˜í”Œ ëŒ€í™” ë°ì´í„° ì‚¬ìš©")
        conversation_data = get_sample_conversation()

    print(f"âœ… ëŒ€í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
    print(f"   â€¢ ì´ {len(conversation_data.get('segments', []))}ê°œì˜ ëŒ€í™” ì„¸ê·¸ë¨¼íŠ¸")
    print(f"   â€¢ ëŒ€í™” ì‹œê°„: {conversation_data.get('duration', 0):.1f}ì´ˆ")

    # í‰ê°€ ëª¨ë“œ ì„ íƒ
    if args.mode == 'detailed':
        print("\n" + "="*80)
        print("ğŸ” ìƒì„¸ í‰ê°€ ëª¨ë“œ - 4ê°€ì§€ í•µì‹¬ ì˜ì—­ ê°œë³„ ë¶„ì„")
        print("="*80)
        print("í‰ê°€ ì˜ì—­:")
        print("  1. ìˆ˜ì„ ê°€ëŠ¥ì„± ë° ë§¤ì¶œ í‰ê°€")
        print("  2. ë²•ë¥  ì „ë¬¸ì„± í‰ê°€")
        print("  3. ëª…í™•í•œ ì˜ì‚¬ì†Œí†µ í‰ê°€")
        print("  4. ì¹œì ˆë„ ë° ê´€ê³„ êµ¬ì¶• í‰ê°€")
        print("="*80)

        start_time = time.time()
        evaluation_result = evaluator.evaluate_detailed(conversation_data)
        elapsed_time = time.time() - start_time

        if "error" not in evaluation_result:
            print(f"\nâ±ï¸  ëª¨ë“  í‰ê°€ ì™„ë£Œ! (ì´ ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ)")

        # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
        evaluator.print_detailed_evaluation(evaluation_result)

    else:
        print("\n" + "="*60)
        print("ğŸ¤– ê°„ë‹¨ í‰ê°€ ëª¨ë“œ")
        print("="*60)

        start_time = time.time()
        evaluation_result = evaluator.evaluate(conversation_data)
        elapsed_time = time.time() - start_time

        if "error" not in evaluation_result:
            print(f"\nâ±ï¸  í‰ê°€ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ)")

        # ê°„ë‹¨ ê²°ê³¼ ì¶œë ¥
        evaluator.print_evaluation(evaluation_result)

    # JSON íŒŒì¼ë¡œ ì €ì¥
    if "error" not in evaluation_result:
        # ìƒì„¸ ëª¨ë“œì¼ ê²½ìš° íŒŒì¼ëª… ìˆ˜ì •
        if args.mode == 'detailed':
            output_file = args.output.replace('.json', '_detailed.json')
        else:
            output_file = args.output

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ í‰ê°€ ê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ëŒ€í‘œ ë³´ê³ ìš© ìš”ì•½ íŒŒì¼ ìƒì„± (ìƒì„¸ ëª¨ë“œë§Œ)
        if args.mode == 'detailed':
            summary_file = args.output.replace('.json', '_executive_summary.txt')
            with open(summary_file, "w", encoding="utf-8") as f:
                f.write("="*80 + "\n")
                f.write("ë¡œíŒ ëŒ€í‘œ ë³´ê³ ì„œ - ìƒë‹´ í’ˆì§ˆ í‰ê°€ ìš”ì•½\n")
                f.write("="*80 + "\n\n")

                # ì¢…í•© í‰ê°€ ìš”ì•½
                comp = evaluation_result.get("comprehensive_evaluation", {})
                if comp and "error" not in comp:
                    f.write(f"ìƒë‹´ì‚¬ ë“±ê¸‰: {comp.get('consultant_rating', 'N/A')}\n\n")
                    f.write(f"ëŒ€í‘œ ìš”ì•½:\n{comp.get('executive_summary', 'N/A')}\n\n")

                    scores = comp.get("summary_scores", {})
                    if scores:
                        f.write("í•µì‹¬ ì ìˆ˜:\n")
                        f.write(f"  â€¢ ìˆ˜ì„ ê°€ëŠ¥ì„±: {scores.get('business_potential', 0)}/100\n")
                        f.write(f"  â€¢ ë²•ë¥  ì „ë¬¸ì„±: {scores.get('legal_expertise', 0)}/100\n")
                        f.write(f"  â€¢ ì˜ì‚¬ì†Œí†µ: {scores.get('communication_clarity', 0)}/100\n")
                        f.write(f"  â€¢ ê³ ê° ì¹œí™”: {scores.get('customer_friendliness', 0)}/100\n\n")

                    if comp.get("action_items"):
                        f.write("ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­:\n")
                        for item in comp.get("action_items", []):
                            f.write(f"  â€¢ {item}\n")

                f.write("\n" + "="*80 + "\n")
            print(f"ğŸ“‹ ëŒ€í‘œ ë³´ê³  ìš”ì•½ì´ '{summary_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"\nâš ï¸  ì˜¤ë¥˜ë¡œ ì¸í•´ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")


# ì‚¬ìš© ì˜ˆì‹œë¥¼ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜
def example_usage():
    """
    ë‹¤ì–‘í•œ ì‚¬ìš© ì˜ˆì‹œ
    """
    # ì˜ˆì‹œ 1: ê¸°ë³¸ ì‚¬ìš©
    evaluator = LegalConsultationEvaluator()
    
    # ì˜ˆì‹œ 2: ì›ê²© ì„œë²„ ì§€ì •
    evaluator = LegalConsultationEvaluator(
        ollama_host="192.168.1.100",  # ì›ê²© ì„œë²„ IP
        ollama_port=11434
    )
    
    # ì˜ˆì‹œ 3: ë„ë©”ì¸ ì´ë¦„ ì‚¬ìš©
    evaluator = LegalConsultationEvaluator(
        ollama_host="ollama.mycompany.com",
        ollama_port=11434
    )
    
    # ëŒ€í™” ë°ì´í„° í‰ê°€
    conversation = get_sample_conversation()
    result = evaluator.evaluate(conversation)
    evaluator.print_evaluation(result)